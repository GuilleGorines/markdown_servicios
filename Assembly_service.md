# How to perform the Assembly Service
Welcome to this (as) brief (as possible) tutorial on how to perform a Assembly Service as a member of the ISCIII's Bioinformatics Unit!

First of all, take the service and place it `in progress` so the solicitant is notified that the service has started. This is a common step for all services provided by BU-ISCIII.

          **INSERT SUPER COOL SCREENSHOT YET TO BE PREPPED**

Now, login in our HPC with your credentials, and go to the appropriate service directory, according to the nature of the service (the center and the area):
```
cd /processing_Data/bioinformatics/services_and_colaborations/SERVICE_CENTER/AREA
```
Create the directory with the Folder Name you are given in the service information, and enter it. This will be the workdir for the service.
```

mkdir $SERVICE_FOLDER_NAME && cd $_
```

Create the directory structure
```
mkdir ANALYSIS DOC RAW REFERENCES RESULTS TMP
```
Move to the RAW directory
```
cd RAW
```
Inside the Service Info Display page, check the name of the sequencing runs that are involved.

Create a symbolic link to the reads that will be used. 
```
ln -s /srv/fastq_repo/$RUNS .
```
Optionally, check how many reads there are, for future references and error tracking. Take into account that the samples might be either *paired-end* or *single-end*.
```
ls | wc -l
```

Move to the ANALYSIS directory
```
cd ../ANALYSIS
```
Record the assembly template path, we will copy all the lablogs from there (of course, this will only work inside the BU-ISCIII file system).

```
ASSEMBLY_TEMPLATE=/data/bi/pipelines/TEMPLATES/ASSEMBLY_TEMPLATE
```

Enter the ANALYSIS directory inside the service, and copy the corresponding lablog from the template. 

```
cp $ASSEMBLY_TEMPLATE/ANALYSIS/lablog .
```

<span style="color:red;"> Check the lablog </span> just in case (do always check the lablog to avoid disasters), then execute it.
```
bash lablog
```








This first lablog will create the following elements:
* <span style="color:#191970 ;">00-reads</span>: directory where the trimmed reads will be stored. 
* <span style="color: #191970;">$(date '+%Y%m%d’)_ANALYSIS01_ASSEMBLY</span>: directory where the analysis will be performed.

Enter this analysis directory.
```
cd *_ANALYSIS01_ASSEMBLY
```
Copy the lablog of this directory from the template.
```
cp $ASSEMBLY_TEMPLATE/ANALYSIS/ANALYSIS01_ASSEMBLY/lablog .
```
Check the lablog and execute.
```
bash lablog
```
The lablog will have created several elements: 
* <span style="color: #279406;">_01_nf_assembly.sh</span>: script to perform the assembly pipeline.
* <span style="color: #191970;">01-preprocessing</span>: directory where preprocessing with Trimmomatic will be performed.
* <span style="color: #191970;">02-kmerfinder</span>: directory where kmerfinder will be performed.
* <span style="color: #191970;">99-stats</span>: directory where kmerfinder results will be stored.
* <span style="color: #191970;">00-reads</span>: symbolic link to the 00-reads directory.
* <span style="color:#1414E0 ;">samples_id</span>: symbolic link to the sample list.
* <span style="color: #1414E0;">bacterial_qc</span>: symbolic link to a directory containing necessary scripts for analysis.

Move to the first step, 01-preprocessing:
```
cd 01-preprocessing
```
Copy the lablog from the 01-preprocessing of a previous service.
```
cp $ASSEMBLY_TEMPLATE/ANALYSIS/ANALYSIS01_ASSEMBLY/01-preprocessing*/lablog .
```
Check the lablog just in case, and execute it.
```
bash lablog
```
 it will create two elements:
 * <span style="color:#279406 ;">_01_preprocess.sh</span>: script to trim the reads with Trimmomatic in the HPC.
 * <span style="color:#279406 ;">_02_pgzip.sh</span>: script to compress the trimmed reads to fastq.gz format in the HPC.

Execute the first script:
```
bash _01_preprocess.sh
```
This will use the HPC to perform the trimming of the samples. If you wish to monitor the state of the submitted Jobs, please use `qstat` (or `watch qstat`, you can exit watch with `ctrl+c`). Once the trimming is finished, check the logs generated by the HPC in this directory. In this case, this command will allow direct confirmation of a successful trimming
```
grep -c "Completed successfully" TRIMMOMATIC.*.o*
```
A single coincidence per log is expected. Please bear in mind that only the files with `.o` extension will contain this message, whereas `.po` files will not. Once ensured, make a directory for the logs, and place all of them in it
```
mkdir logs
mv TRIMMOMATIC* logs
```
Execute the second script to compress the trimmed files
```
bash _02_pgzip.sh
```
Once finished, move the PGZIP to the logs (these are empty, or at least they should be)
```
mv PGZIP* logs
```
Go to the next part, 02-kmerfinder
```
cd ../02-kmerfinder
```
Again, copy the lablog from the 02-kmerfinder of the template

```
cp $ASSEMBLY_TEMPLATE/ANALYSIS/ANALYSIS01_ASSEMBLY/02-kmerfinder/lablog .
```

Check the lablog, and execute it
```
bash lablog
```

It will create three scripts:
* <span style="color: #279406;">_00_kmerfinder.sh</span>: will run kmerfinder in the HPC to find the correct reference for the service.
* <span style="color: #279406;">_02_find_common_reference.sh</span>: will *only* display the kmerfinder top-hits.
* <span style="color: #279406;">_03_download_reference.sh</span>: will download the most common top-hit and place it inside the REFERENCES directory.

Load the <span style="color:#1D315F;font-style: italic;">Singularity</span> module so kmerfinder can be executed
```
module load singularity/singularity-2.6.0
```
Execute the first script
```
bash _00_kmerfinder.sh
```
Create the directory for logs:
```
mkdir logs
```
Once the kmerfinder process is over, move the KMERFINDER logs to logs
```
mv KMERFINDER* logs
```
Execute the second script. This will display the top-hits for kmerfinder. Make sure to check if the top-hits make sense, otherwise check if everything has gone alright, or even contact the service solicitant.
```
bash _02_find_common_reference.sh
```
Execute the third script. This will download the most common top-hit assembly (the first one if tied), in faa, fna and gff format, and place all of them inside the references directory.

```
bash _03_download_reference.sh
```

Exit the directory.
```
cd ..
```
As we will run the nf assembly pipeline, we will activate the appropriate <span style="color: #40AB29; font-style: italic">conda</span> environment for it.
```
conda activate nextflow
```
Now, we will change the reference used in the `_01_nf_assembly.sh` script to the reference we just downloaded (dont include the `_genomic` part).
```
sed -i “s/@@@@@/your_reference/g” _01_nf_assembly.sh
```
Once changed, execute the script in the background (so it cant be interrupted if connection to the HPC is lost).
```
nohup bash _01_nf_assembly.sh &> $(date '+%Y%m%d')_assembly01.log &
```
While the previous script is running, go to 99-stats to generate the statistics of the kmerfinder step.
```
cd 99-stats
```
Copy the lablog from the 99-stats folder of the service template.
```
cp $ASSEMBLY_TEMPLATE/ANALYSIS/ANALYSIS01_ASSEMBLY/99-stats/lablog . 
```

Check the lablog and execute it (this one will do all the work).
```
bash lablog
```

Once all of these steps have ended, the service will be finished. However, there are some extra steps to take into account before delivery.

## Preparing the delivery

Before delivering the service, it is necessary to **remove not-so-useful and redundant data** (such as the trimmed reads). Go to the main directory of the service.
```
cd ../../..
```

Change the name of the `RAW` and `TMP` directories, adding a _NC (no copy) to their names
```
mv RAW RAW_NC
mv TMP TMP_NC
```
Then, go to `ANALYSIS/*_ANALYSIS01_ASSEMBLY`

```
cd ANALYSIS/*_ANALYSIS01_ASSEMBLY
```
The only files needed inside of `01-preprocessing` are the logs, and the lablog, so delete everything there except for those.
```
cd 01-preprocessing 
rm -rf -v !("lablog"|"logs")
``` 

Go back and change the name of `01-preprocessing`, adding a _DEL (delete)
```
cd ..
mv 01-preprocessing 01-preprocessing_DEL
```
The work directory generated by nextflow takes a lot of space, and its not necessary, so deleting it will safe us that precious disk capacity.
```
rm -rf work
```
Inside the `03-assembly` directory, there are some trimmed reads.
```
cd 03-assembly
rm -rf trimming/trimmed/*
```
Changing that `trimmed` directory to `trimmed_DEL` will end this part of the guide.
```
mv trimming/trimmed trimming/trimmed_DEL
``` 

With all of this, the service is ready to be delivered. However, the result revision is still pending.

## In short
Here, we gather all the above steps without an explanation, so the service can be launched in a blast. However, take into account that you should always check the lablogs.

ASSEMBLY_TEMPLATE="/data/bi/pipelines/TEMPLATES/NEW_ASSEMBLY_TEMPLATE"
mkdir $SERVICE_FOLDER_NAME && cd $_

mkdir ANALYSIS DOC RAW REFERENCES RESULTS TMP
cd RAW
*fill raw directory*

cp $ASSEMBLY_TEMPLATE/DOC/hpc_slurm_assembly.config DOC
cd ANALYSIS
cp $TEMPLATE/ANALYSIS/lablog .
bash lablog
ls
ls *ANALYSIS01_ASSEMBLY
bash _01_copy_folder.sh

cd /data/bi/scratch_tmp/bi/$SERVICE_FOLDER_NAME
cd ANALYSIS/*ANALYSIS01*
cp $ASSEMBLY_TEMPLATE/ANALYSIS/ANALYSIS01_ASSEMBLY/lablog .
bash lablog [ + / - ]
module load Nextflow singularity
bash _01_nf_assembly.sh



## Revising the results

Once all processes have ended (remember to always check this with `qstat`), its time to go over the results.

First of all, check the **quality of the reads**. This can be checked in the `03-assembly` directory. FastQC and MultiQC reports can be found there.

Secondly, check the **quality of the assembly**. A Quast report can be found in `03-assembly`.

Last, but not least, check the kmerfinder csv generated in `99-stats` to see if there are hints of **contamination**.

Make sure to take note of any anomalies. Sometimes something might be off, or might not make sense. Try to find a reason for this (wrong parameters in a process, not-so-good quality of the reads). Maybe, repeating the process with some changes is necessary, take note of that as well.



## Troubleshooting

Sometimes, incidences ocurr. Here, we register all troubleshooting to try and help solve it fast and easy.

**Wrong reference** (21-9-2021): sometimes, investigators provide their samples stating that they belong to a certain organism. The kmerfinder result might prove this right, or not. If the results agree with the investigator, the analysis can continue. Hoever, if it does not, please note it down before proceeding.   
	
	
**User namespace** (22-9-2021): 
Found in: kmerfinder process

Description: kmerfinder process stopped early, and logs showed the following message:

`ERROR : Failed to create user namespace: user namespace not supported by your system`

Solution: Restarting the ssh connection worked

**NEWUSER namespace runtime** (15-2-2022)
Found in: kmerfinder process

Description: kmerfinder process stopped early, logs showed the following message:

`Failed invoking the NEWUSER namespace runtime: Invalid argument`
`ABORT  : Retval = 255`


	
